{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYUprMJvNOnmFSjN4imcWZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramonVDAKKER/teaching-data-science-emas/blob/main/notebooks/short_standard_demo_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgFB9rhmv-VC"
      },
      "source": [
        "# Snippets for in-class demo and discussion of image classification and transfer learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2UVDj07wBS9"
      },
      "source": [
        "## 0. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2A2TnFevwHp"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from urllib import request\n",
        "from io import BytesIO\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZz8rihnwJP9"
      },
      "source": [
        "## 1. Load model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVfwVLvLwN_K"
      },
      "source": [
        "We load the InceptionV3 model which is included in the keras package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEUt19tYwGas"
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "model = InceptionV3()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypOmVORqwxpy"
      },
      "source": [
        "# 2. Using the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx_Ygqhhx48P"
      },
      "source": [
        "Choose a photo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhcrqXYkx8m4"
      },
      "source": [
        "url = \"https://kc-shertogenbosch.nl/wp-content/uploads/2018/11/Nederlandse-Schapendoes.jpg\"\n",
        "res = request.urlopen(url).read()\n",
        "image = Image.open(BytesIO(res)).resize((299, 299))\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVghrGq_3Ki8"
      },
      "source": [
        "Transform the image to numerical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UskU5fldyRnq"
      },
      "source": [
        "image = img_to_array(image)\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "image = preprocess_input(image)\n",
        "print(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcyBkYnI3TY-"
      },
      "source": [
        "Use the model to classify the image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhC7ET6lhMfd"
      },
      "source": [
        "model.predict(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLx-f5nzz8vX"
      },
      "source": [
        "predicted_label = decode_predictions(model.predict(image))\n",
        "for item in predicted_label[0]:\n",
        "  print(f\"Label {item[1]} has probability: {item[2]}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9ieiBTUyivq"
      },
      "source": [
        "## 3. Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1303tID5zLe"
      },
      "source": [
        "Code partially taken from https://www.tensorflow.org/hub/tutorials/tf2_image_retraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFg1mq9659a8"
      },
      "source": [
        "Load dataset with flower images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfeFWnPo0_tH"
      },
      "source": [
        "data_dir = tf.keras.utils.get_file(\"flower_photos\",\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\", untar=True)\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1. / 255)\n",
        "def build_dataset(subset):\n",
        "  dataset = tf.keras.preprocessing.image_dataset_from_directory(data_dir,\n",
        "      validation_split=.30,\n",
        "      subset=subset,\n",
        "      label_mode=\"categorical\",\n",
        "      seed=123,\n",
        "      image_size=(299, 299),\n",
        "      batch_size=1)\n",
        "  size = dataset.cardinality().numpy()\n",
        "  classes = tuple(dataset.class_names)\n",
        "  dataset = dataset.unbatch().batch(32)\n",
        " # dataset = dataset.repeat()\n",
        "  dataset = dataset.map(lambda images, labels: (normalization_layer(images), labels))\n",
        "  #dataset = dataset.map(lambda images, labels: (preprocess_input(images), labels))\n",
        "  return dataset, classes, size\n",
        "train_data, class_names, train_size = build_dataset(\"training\")\n",
        "validation_data, _, validation_size = build_dataset(\"validation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j_-4NnnMJoz"
      },
      "source": [
        "Let us inspect a few images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZs1n1K20Htj"
      },
      "source": [
        "x, y = next(iter(validation_data))\n",
        "k = 5\n",
        "predicted_label = decode_predictions(model.predict(x[0 : k, :, :, :]))\n",
        "for i in range(0, k):\n",
        "  image = x[i, :, :, :]\n",
        "  true_index = np.argmax(y[i])\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.title(class_names[true_index])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX7rYZO19zor"
      },
      "source": [
        "InceptionV3, with our setting to consider 1,000 classes, is not specific enough to distinguish the flowers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT7ZPCa50kk6"
      },
      "source": [
        "for item in predicted_label[i]:\n",
        "  print(f\"Label {item[1]} has probability: {item[2]}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew87QGiC-Fuz"
      },
      "source": [
        "Using the small (!) flower dataset and InceptionV3 we will train a neural network. First we specify the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvL7uwnp_bwF"
      },
      "source": [
        "base_model = InceptionV3(include_top=False, input_shape=(299, 299) + (3,))\n",
        "base_model.trainable = False\n",
        "model = Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(299, 299) + (3,)),\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5\", trainable=False),\n",
        "    tf.keras.layers.Dropout(rate=0.4),\n",
        "    tf.keras.layers.Dense(5, kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "model.build([None, 299, 299, 3])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JpUClCPdEnHH"
      },
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.SGD(),\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
        "  metrics=['accuracy'])\n",
        "steps_per_epoch = train_size // 32\n",
        "validation_steps = validation_size // 32\n",
        "hist = model.fit(train_data, epochs=50, steps_per_epoch=steps_per_epoch, validation_data=validation_data).history"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}