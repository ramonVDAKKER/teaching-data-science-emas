{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF5fEmkHqKDD3mk9EYlo8/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramonVDAKKER/teaching-data-science-emas/blob/main/notebooks/emas_case1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Case 1"
      ],
      "metadata": {
        "id": "2cRgyu8NIUJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Imports"
      ],
      "metadata": {
        "id": "nawY9AWfIV6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download files from GitHub:"
      ],
      "metadata": {
        "id": "3eyuwSaE8vva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/ramonVDAKKER/teaching-data-science-emas\n",
        "import os\n",
        "os.chdir(\"teaching-data-science-emas/notebooks\")"
      ],
      "metadata": {
        "id": "qhOcGI_wIVK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important packages for Python are <a href=\"http://www.numpy.org/\">numpy</a> (for arrays, linear algebra, pseudorandom numbers etc.), <a href=\"http://pandas.pydata.org/\">pandas</a> (contains convenient data structure called \"pandas dataframe\"), <a href=\"http://matplotlib.org/\">matplotlib</a> & <a href=\"http://seaborn.pydata.org/\"> seaborn</a> (for data visualisation), <a href=\"http://scikit-learn.org/stable/\">sklearn</a> (scikit-learn; powerful package containing machine & statistical learning functions), and  <a href=\"https://www.statsmodels.org/stable/index.html\">statsmodels</a> for statistical models and routines."
      ],
      "metadata": {
        "id": "v1dsITd47tUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import confusion_matrix,  accuracy_score, roc_auc_score, precision_recall_curve, RocCurveDisplay\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "xnF8iwqqJd1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also use the pandas-profiling package which requires a nonstandard installation process on Colab:"
      ],
      "metadata": {
        "id": "oOwisMXZ6DFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip\n",
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "metadata": {
        "id": "dut6FJVA6AaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "sR7TK6O67QH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load dataset & Elementary Data Analysis"
      ],
      "metadata": {
        "id": "HvuKlb0GIx0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Load and inspect data"
      ],
      "metadata": {
        "id": "5s1LBJAZ6iCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset into a pandas dataframe:"
      ],
      "metadata": {
        "id": "ROx94hHs85vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"./data/case_1/DataTrain.csv\")"
      ],
      "metadata": {
        "id": "Jv3_3dFKIuQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the first dataset into a \"train set\" and a \"validation set\"."
      ],
      "metadata": {
        "id": "ABbImfZ9kKAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 123\n",
        "train_df, aux_df = train_test_split(dataset, train_size=.5, random_state=seed)\n",
        "validation_df, test_df = train_test_split(aux_df, train_size=.5, random_state=seed)\n",
        "\n",
        "print(f\"data_train shape: {train_df.shape}\")\n",
        "print(f\"data_validation shape: {validation_df.shape}\")\n",
        "print(f\"data_test shape: {test_df.shape}\")\n",
        "del dataset"
      ],
      "metadata": {
        "id": "k16cBhaGkJFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us inspect the first 3 and the last 3 rows of the dataset:"
      ],
      "metadata": {
        "id": "ngCpcTOGJ5pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = 100\n",
        "display(train_df.head(3))\n",
        "display(train_df.tail(3))"
      ],
      "metadata": {
        "id": "xvhc1U7cJ1Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some meta-data:"
      ],
      "metadata": {
        "id": "eeLuV38tKLhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "PMWuEDbTKR7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See below for a description of the columns.\n",
        "\n",
        "**Data fields:**\n",
        "\n",
        "1.    *CustomerID* - Customer ID (Unique ID to identify the customer)\n",
        "\n",
        "2.   *Age* - Age of customer (Numeric)\n",
        "\n",
        "3.    *Sex* - Gender of customer (Categorical: \"M\" - Male,\"F\" - Female)\n",
        "\n",
        "4.    *Job* - Type of job (Categorical: \"admin.\",\"blue-collar\",\"entrepreneur\",\"housemaid\",\"management\",\"retired\",\"self-employed\",\"services\",\"student\",\"technician\",\"unemployed\",\"unknown\")\n",
        "\n",
        "5.    *Marital_Status* - Marital status (Categorical: \"divorced\",\"married\",\"single\",\"unknown\"; note: \"divorced\" means divorced or widowed)\n",
        "\n",
        "6.    *Education_Level* - Education Level (Categorical: \"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"illiterate\",\"professional.course\",\"university.degree\",\"unknown\")\n",
        "\n",
        "7.    *Credit_Default* - Has credit default? (Categorical: \"no\",\"yes\",\"unknown\")\n",
        "\n",
        "8.    *Housing_Loan* - Has housing loan? (Categorical: \"no\",\"yes\",\"unknown\")\n",
        "\n",
        "9.    *Personal_Loan* - Has personal loan? (Categorical: \"no\",\"yes\",\"unknown\")\n",
        "\n",
        "10.    *Contact_Method* - Contact communication type for current campaign (Categorical: \"cellular\",\"telephone\")\n",
        "\n",
        "11.    *Contact_Month* - Last contact month for current campaign (Categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
        "\n",
        "12.    *Contact_WeekDay* - Last contact day of the week for current campaign (Categorical: \"mon\",\"tue\",\"wed\",\"thu\",\"fri\")\n",
        "\n",
        "13.    *NoContacts_Current_Campaign* - Number of contacts performed during current campaign and for this client (Numeric, includes last contact)\n",
        "\n",
        "14.    *Pdays* - Number of days that passed by after the client was last contacted from a previous campaign (Numeric: 999 means client was not previously contacted. However, please note that some records contain no of previous contacts for 999)\n",
        "\n",
        "15.    *NoContacts_PrevCampaigns* - Number of contacts performed before this campaign and for this client (Numeric)\n",
        "\n",
        "16.    *Prev_Outcome* - Outcome of the previous marketing campaign (Categorical: \"failure\",\"nonexistent\",\"success\")\n",
        "\n",
        "17.    *Emp_Var_Rate* - Employment Variation Rate - Quarterly indicator (Numeric)\n",
        "\n",
        "18.    *Monthly_CPI* - Consumer Price Index - Monthly indicator (Numeric)\n",
        "\n",
        "19.    *Monthly_CCI* - Consumer Confidence Index - Monthly indicator (Numeric)\n",
        "\n",
        "20.    *Euribor3m* - Euribor 3 month rate - Daily indicator (Numeric)\n",
        "\n",
        "21.    *No_Employed* - Number of employees - Quarterly indicator (Numeric)\n",
        "\n",
        "22.    *Outcome* - Has the customer subscribed a term deposit? (Binary: 1 - means yes, 0 means no)"
      ],
      "metadata": {
        "id": "3jcBuIpYI5mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Summary statistics"
      ],
      "metadata": {
        "id": "YnDq6WNYNksV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "RTt5CT5eI6R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Cleansing"
      ],
      "metadata": {
        "id": "x2-0heBuQjZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for missing values:"
      ],
      "metadata": {
        "id": "DpIldi4E8K1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isnull().sum()"
      ],
      "metadata": {
        "id": "cu0Mw3uJ8F8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the variable *Pdays* (see description):"
      ],
      "metadata": {
        "id": "a5gJEeS69CG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum((train_df[\"Pdays\"]==999) & (train_df[\"NoContacts_PrevCampaigns\"] > 0)))\n",
        "print(sum((train_df[\"Pdays\"]==999) & (train_df[\"Prev_Outcome\"] == \"success\")))\n",
        "print(sum((train_df[\"Pdays\"]==999) & (train_df[\"Prev_Outcome\"] == \"failure\")))"
      ],
      "metadata": {
        "id": "xfXZbYBP-VDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean:"
      ],
      "metadata": {
        "id": "HNB6ngpk_EBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.loc[train_df[\"Pdays\"]==999, \"NoContacts_PrevCampaigns\"] = 0\n",
        "train_df.loc[train_df[\"Pdays\"]==999, \"Prev_outcome\"] = \"nonexistent\""
      ],
      "metadata": {
        "id": "1isqj_wlQlS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Univariate plots"
      ],
      "metadata": {
        "id": "6BVzMrR9QnCB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution target variable:"
      ],
      "metadata": {
        "id": "rKvzp3X_7rII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recall, from the description of the data, that Outcome=1 corresponds to a subscription to a term deposit (within a specified time horizon).\")   \n",
        "print(f\"The data type of the target is {type(train_df['Outcome'].loc[0])}\\n\")\n",
        "print(\"The distribution of the target in the train set:\")\n",
        "aux = train_df[\"Outcome\"].value_counts()\n",
        "display(aux)\n",
        "print(f\"\\nThe frequency of observations with Y=1 equals (in the train set): {np.round(100 * aux.loc[1] / aux.sum(), 1)}%\")"
      ],
      "metadata": {
        "id": "ynnju7rOWnyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_var = [\"Age\", \"NoContacts_Current_Campaign\", \"Pdays\", \"NoContacts_PrevCampaigns\", 'Emp_Var_Rate', 'Monthly_CPI', 'Monthly_CCI', 'Euribor3m', 'No_Employed']\n",
        "cat_var = [\"Sex\", \"Job\", \"Marital_Status\", \"Education_Level\", \"Credit_Default\", \"Housing_Loan\", \"Personal_Loan\", \"Contact_Method\", \"Contact_Month\", \"Contact_WeekDay\", \"Prev_Outcome\"]"
      ],
      "metadata": {
        "id": "87mGPJ8fA5a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histograms for numerical variables:"
      ],
      "metadata": {
        "id": "VrIGPfWn7v8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[num_var].hist(bins=50, figsize=(15, 15))"
      ],
      "metadata": {
        "id": "Bwt2ilbDXxXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots for categorical variables:"
      ],
      "metadata": {
        "id": "ZxiDpmTq71ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for var in cat_var:\n",
        "    train_df[var].value_counts().plot(kind=\"bar\", title=f\"Frequency distribution variable {var}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mWihk9ZwBzwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Bivariate plots"
      ],
      "metadata": {
        "id": "LnVpK3aEQwkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation between variables:"
      ],
      "metadata": {
        "id": "XEg3UkCq8Bjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.corr(method=\"pearson\")"
      ],
      "metadata": {
        "id": "L9dXHFWCV0uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def VizCorrelationMatrix(df):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax1 = fig.add_subplot(111)\n",
        "    cmap = cm.get_cmap(\"jet\", 30)\n",
        "    cax = ax1.imshow(df.corr(), interpolation=\"nearest\", cmap=cmap)\n",
        "    ax1.grid(True)\n",
        "    plt.title(\"Estimated Correlation Matrix\")\n",
        "    fig.colorbar(cax, ticks=[.75, .8, .85, .90, .95, 1])\n",
        "    plt.show()\n",
        "VizCorrelationMatrix(train_df[num_var])\n",
        "print(pd.DataFrame(num_var, columns=[\"Name feature\"]))"
      ],
      "metadata": {
        "id": "QHJfD2O0V8mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots of distribution of X|Y=1 and X|Y=0 for numerical variables:"
      ],
      "metadata": {
        "id": "o1hWPDJj8WHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z = train_df.copy()\n",
        "for name in num_var:\n",
        "    print(\"Consider feature \" + name + \":\")\n",
        "    x = Z.where(Z[\"Outcome\"]==1)[name]\n",
        "    y = Z.where(Z[\"Outcome\"]==0)[name]\n",
        "    left =min(np.nanmin(x), np.nanmin(y))\n",
        "    right =max(np.nanmax(x), np.nanmax(y))\n",
        "    plt.hist([x, y], bins=25, range=[left, right], label=['1', '0'], density=True)\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "g55507z4YaQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Via box plots:"
      ],
      "metadata": {
        "id": "FJnpaQUdIGGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for var in num_var:\n",
        "    train_df.boxplot(column=var, by=\"Outcome\")"
      ],
      "metadata": {
        "id": "TNkJiADRIIo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empirical P(Y=1|X=x) for categorical  variables:"
      ],
      "metadata": {
        "id": "bJH7n69GU8Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for var in cat_var:\n",
        "    train_df.groupby(var).agg({\"Outcome\": \"mean\"}).plot(kind=\"bar\", title=f\"Empirical P(Y=1|X=x) for variable {var}\")"
      ],
      "metadata": {
        "id": "IsGkzxB4UrTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elementary data analysis using pandas-profiling:"
      ],
      "metadata": {
        "id": "FnCO8Hdp8ke_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(train_df, title=\"Data report train set\")\n",
        "profile.to_notebook_iframe()"
      ],
      "metadata": {
        "id": "hTfG4iWO8lr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions:\n",
        "*   Can you explain the observed patterns for Monthly_CPI, Monthly_CCI and Euribor3m?\n",
        "*   What do you think of the data quality?\n",
        "*   We have used the \"train dataset\" for the data analysis? Should we have included the \"validation set\" and \"test set\" as well? If not: should we carry out additional analyses?\n",
        "*   Which variables do you consider promising for modelling?\n"
      ],
      "metadata": {
        "id": "vHKXSE2HiPrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Feature engineering"
      ],
      "metadata": {
        "id": "Z2tI5R5yWokW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build datasets with dummies for categorical variables:"
      ],
      "metadata": {
        "id": "NDlZ35izWyAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_dummies(df, cat_var):\n",
        "    \"\"\"Return new dataframe with dummy variables for specified categorical variables.\"\"\"\n",
        "    dummies_df = pd.DataFrame()\n",
        "    for var in cat_var:\n",
        "        aux = pd.get_dummies(df[[var]], prefix=f\"ind_{var}\", drop_first=False)\n",
        "        dummies_df = pd.concat([dummies_df, aux], axis=1)\n",
        "    return dummies_df\n",
        "\n",
        "def build_X_y(df, num_var, cat_var, name_target):\n",
        "    \"\"\"Build datasets X, y for modelling.\"\"\"\n",
        "    num_df = df.copy()[num_var]\n",
        "    dum_df = add_dummies(df, cat_var)\n",
        "    X = pd.concat([num_df, dum_df], axis=1)\n",
        "    y = df[name_target]\n",
        "    return X, y\n",
        "\n",
        "name_target = \"Outcome\"\n",
        "X_train, y_train =  build_X_y(train_df, num_var, cat_var, name_target)\n",
        "X_validation, y_validation =  build_X_y(validation_df, num_var, cat_var, name_target)\n",
        "X_test, y_test =  build_X_y(test_df, num_var, cat_var, name_target)\n",
        "# ensure common columns\n",
        "cols = set(X_train.columns).intersection(set(X_validation.columns)).intersection(set(X_test.columns))\n",
        "X_train = X_train[cols]\n",
        "X_validation = X_validation[cols]\n",
        "X_test = X_test[cols]"
      ],
      "metadata": {
        "id": "0FLzobyBV_BY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Logit model"
      ],
      "metadata": {
        "id": "6PSY_i5dRZPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Available features:"
      ],
      "metadata": {
        "id": "So6dbIJ_ckBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.columns)"
      ],
      "metadata": {
        "id": "tyRCVwjwchED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = [\"ind_Prev_Outcome_success\", \"ind_Contact_Method_telephone\", \"ind_Contact_Month_may\"]"
      ],
      "metadata": {
        "id": "CctZdpsvcfXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we fit a logistic regression using the Scikit-learn package (for machine learning):"
      ],
      "metadata": {
        "id": "V-fb3qRzfJ5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logit = LogisticRegression(penalty=\"none\")"
      ],
      "metadata": {
        "id": "5AVZw7m0bj6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit.fit(X_train[selected_features], y_train)"
      ],
      "metadata": {
        "id": "HquFzBenb-1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estimated coefficients:"
      ],
      "metadata": {
        "id": "7jicHDQ0dvWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "est_coef = pd.DataFrame(logit.coef_.T, index=selected_features, columns=[\"estimated coefficient\"])\n",
        "est_coef.loc[\"intercept\", \"estimated coefficient\"] = logit.intercept_\n",
        "display(est_coef)"
      ],
      "metadata": {
        "id": "coQ-2keud6vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The estimated probabilities Y=1:"
      ],
      "metadata": {
        "id": "a6cU49fypo2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs_train = logit.predict_proba(X_train[selected_features])[:, 1]\n",
        "plt.hist(probs_train)"
      ],
      "metadata": {
        "id": "hEG-mtJtwOgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A standard Logistisc regression can also be fitted with the statsmodels package."
      ],
      "metadata": {
        "id": "upU2Pq6JfSeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logit_sm = sm.Logit(y_train,  sm.add_constant(X_train[selected_features])).fit()"
      ],
      "metadata": {
        "id": "UzcF2939fRwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(logit_sm.summary())"
      ],
      "metadata": {
        "id": "mRmM39-0fli-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "y_pred_train = (logit.predict_proba(X_train[selected_features])[:, 1] > threshold)"
      ],
      "metadata": {
        "id": "qLPo_mRIfR4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(hat_y, y, target_values):\n",
        "    matrix = confusion_matrix(y, hat_y)  # note that true label corresponds to first argument\n",
        "    sns.heatmap(matrix.T, square=True, annot=True, fmt=\"d\", cbar=False,\n",
        "    xticklabels=target_values, yticklabels=target_values)\n",
        "    plt.xlabel(\"true label\")\n",
        "    plt.ylabel(\"predicted label\")\n",
        "    accuracy = accuracy_score(y, hat_y, normalize=True, sample_weight=None)\n",
        "    print(\"The accuracy is \" + str(np.round(100*accuracy,1)) + \"%\")\n",
        "\n",
        "plot_confusion_matrix(y_pred_train , y_train, [0, 1])"
      ],
      "metadata": {
        "id": "4FMZ5CXPxnn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc(y, hat_prob_y):\n",
        "    RocCurveDisplay.from_predictions(\n",
        "        y,\n",
        "        hat_prob_y,\n",
        "        name=\"ROC curve\",\n",
        "        color=\"darkorange\",\n",
        "    )\n",
        "    plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
        "    plt.axis(\"square\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC curve\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_roc(y_train, probs_train)"
      ],
      "metadata": {
        "id": "Wh_exa_6yZe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**: evaluate performance on validation set"
      ],
      "metadata": {
        "id": "537nPPWU1e4N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGmvZLajSXUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision tree"
      ],
      "metadata": {
        "id": "h3RtT-y58boJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = tree.DecisionTreeClassifier(max_depth=40)\n",
        "model_tree = clf.fit(X_train, y_train)\n",
        "ax = plt.figure(figsize=(25, 25))\n",
        "tree.plot_tree(model_tree, max_depth=3, filled=True, fontsize=10)"
      ],
      "metadata": {
        "id": "JUvF1XAJ8dgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hat_target_train_tree = model_tree.predict(X_train)\n",
        "\n",
        "plot_confusion_matrix(hat_target_train_tree, y_train, [0, 1])\n",
        "plot_roc(y_train,  model_tree.predict_proba(X_train)[:, 1] )"
      ],
      "metadata": {
        "id": "uF2gBcrR8eWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** evaluate performance on the validation set"
      ],
      "metadata": {
        "id": "dIETTjYgTmeh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "65DSv8ho9klE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question:  investigate impact of the 'max_depth' parameter."
      ],
      "metadata": {
        "id": "FHEhmHoO_4fN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FMWXhYwa_vWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest"
      ],
      "metadata": {
        "id": "kAUpvRs6AAJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators=250, random_state=123)\n",
        "rf = clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "EKhSEcS5ABtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hat_target_train_rf = rf.predict(X_train)\n",
        "\n",
        "plot_confusion_matrix(hat_target_train_rf, y_train, [0, 1])\n",
        "plot_roc(y_train,  rf.predict_proba(X_train)[:, 1] )"
      ],
      "metadata": {
        "id": "P5FUg3GrAO4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** investigate performance on the validation set.\n",
        "\n",
        "**Question:** Consider the documentation of Scikit and investigate impact of max_depth."
      ],
      "metadata": {
        "id": "d297_qQcT1Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8QXe5dxZAYkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Xgboost"
      ],
      "metadata": {
        "id": "izRxUdOwShs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = xgb.XGBClassifier()\n",
        "xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "x2z2WlodAlg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hat_target_train_xgb = xgb.predict(X_train)\n",
        "\n",
        "plot_confusion_matrix(hat_target_train_xgb, y_train, [0, 1])\n",
        "plot_roc(y_train, xgb.predict_proba(X_train)[:, 1] )"
      ],
      "metadata": {
        "id": "kS74VBrzUZ6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question**: determine performance on validation set"
      ],
      "metadata": {
        "id": "rpCebl7-Uo4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hat_target_train_xgb = xgb.predict(X_validation)\n",
        "\n",
        "plot_confusion_matrix(hat_target_train_xgb, y_validation, [0, 1])\n",
        "plot_roc(y_validation, xgb.predict_proba(X_validation)[:, 1] )"
      ],
      "metadata": {
        "id": "a6_RGH1rUkcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XB1Eh4eSU1DB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}